{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Sentinel-2 burned area identification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook prepares the data transformation application: The outcome is a data transformation application that takes one input (or a set of inputs organized in an atomic unit) and generates the output.\n",
    "\n",
    "The application implements:\n",
    "\n",
    "* Calculation of NDVI in the two scenes (using band 8 and 4), (B8-B4)/(B8+B4)\n",
    "* Calculation of NDWI, in the two scenes (using band 8 and 11), (B8-B11)/(B8+B11)\n",
    "* If NDWI i2 - NDWI i1 > 0.18 and If NDVI i2 - NDVI i1 > 0.19 then burned pixels\n",
    "\n",
    "The outputs generated include:\n",
    "\n",
    "* COG RGB composite with bands 12, 11, 8A pre\n",
    "* COG RGB composite with bands 12, 11, 8A post \n",
    "* COG scene classification pre  \n",
    "* COG scene classification post \n",
    "* COG 8 bits with bitmask burned/not burned\n",
    "* Geojson with vectorization of bitmask burned/not burned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "service = dict([('title', 'Sentinel-2 burned area identification'),\n",
    "                ('abstract', 'This is a short description'),\n",
    "                ('id', 'ewf-satcen-03-03-02')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Definition "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runtime parameter definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input reference**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_threshold = dict([('id', 'pp_threshold'),\n",
    "                     ('title', 'Post Processing threshold in pixels'),\n",
    "                     ('abstract', 'Number of pixels composing the isolated polygon to be removed (if 0 no post processing is applied)'),\n",
    "                     ('value', '3'),\n",
    "                     ('maxOccurs', '0'),\n",
    "                     ('maxOccurs', '1')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_threshold = dict([('id', 'ndvi_threshold'),\n",
    "                       ('value', '0.19'),\n",
    "                       ('title', 'NDVI difference threshold'),\n",
    "                       ('abstract', 'NDVI difference threshold'),\n",
    "                       ('maxOccurs', '1')]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndwi_threshold = dict([('id', 'ndwi_threshold'),\n",
    "                   ('value', '0.18'),\n",
    "                   ('title', 'NDWI difference threshold'),\n",
    "                   ('abstract', 'NDWI difference threshold'),\n",
    "                   ('maxOccurs', '1')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wkt = dict([('id', 'aoi'),\n",
    "            ('value', 'POLYGON((149.74042460751588 -34.29772543048931,150.93246853304504 -34.323665099129535,150.90758708373184 -35.313155442237914,149.70124915286058 -35.28624837182783,149.74042460751588 -34.29772543048931))'),\n",
    "            ('title', 'Area of interest'),\n",
    "            ('abstract', 'Area of interest in WKT or bounding box')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_references = ['https://catalog.terradue.com/sentinel2/search?uid=S2A_MSIL2A_20191101T000241_N0213_R030_T56HKG_20191101T020007',\n",
    "                    'https://catalog.terradue.com/sentinel2/search?uid=S2A_MSIL2A_20200320T000241_N0214_R030_T56HKG_20200320T020042']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data path**\n",
    "\n",
    "This path defines where the data is staged-in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = '/workspace/data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "import snappy\n",
    "from snappy import ProductIO\n",
    "from snappy import GPF\n",
    "from snappy import WKTReader\n",
    "S2CacheUtils = snappy.jpy.get_type('org.esa.s2tbx.dataio.cache.S2CacheUtils')\n",
    "S2CacheUtils.deleteCache()\n",
    "\n",
    "import cioppy\n",
    "ciop = cioppy.Cioppy()\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import gdal\n",
    "import geopandas as gp\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "sys.path.append(os.getcwd())\n",
    "sys.path.append('/application/notebook/libexec/') \n",
    "from helpers import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "gdal.UseExceptions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = get_metadata(input_references, data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_analysis(products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "req_bands = ['B4','B8','B8A', 'B11','B12', 'quality_scene_classification' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geom = WKTReader().read(wkt['value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### If more than one post or pre products==> use slice assembly ==>use new mosaics as input to the next steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_files = []\n",
    "for index, item in enumerate(['Pst','Pre']):\n",
    "    if(products[products['ordinal_type'] == item].identifier.count()>1):\n",
    "        product = mosaic_inputs(products[products['ordinal_type'] == item].reset_index(drop=True))\n",
    "    else:\n",
    "        local_pathx=products[products['ordinal_type'] == item].iloc[0]['local_path']\n",
    "        s2prd = \"%s/MTD_MSIL2A.xml\" %local_pathx \n",
    "        product = snappy.ProductIO.readProduct(s2prd)\n",
    "    \n",
    "    output_name = '%s_%s.tif'%(item,product.getName())\n",
    "    \n",
    "    product = resample2ref_band(product,'B4')\n",
    "    \n",
    "    product = subset_to_aoi_reduce_bands(product,geom,req_bands)\n",
    "   \n",
    "    ProductIO.writeProduct(product, 'S2_{}_tmp.tif'.format(item), 'GeoTIFF-BigTIFF')\n",
    "    \n",
    "    output_files.append('RGB_{}'.format(output_name))\n",
    "    snap_rgb(product,['B12','B11','B8A'],'RGB_{}'.format(output_name))\n",
    "    \n",
    "    product.dispose()\n",
    "    S2CacheUtils.deleteCache()\n",
    "    \n",
    "print(output_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NDVI & NDWI computation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = gdal.Open('S2_Pre_tmp.tif')\n",
    "    \n",
    "pre_b04 = ds.GetRasterBand(1).ReadAsArray()\n",
    "pre_b08 = ds.GetRasterBand(2).ReadAsArray()\n",
    "pre_b11 = ds.GetRasterBand(4).ReadAsArray()\n",
    "pre_scl = ds.GetRasterBand(6).ReadAsArray()\n",
    "\n",
    "ds = None\n",
    "\n",
    "os.remove('S2_Pre_tmp.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = gdal.Open('S2_Pst_tmp.tif')\n",
    "    \n",
    "post_b04 = ds.GetRasterBand(1).ReadAsArray()\n",
    "post_b08 = ds.GetRasterBand(2).ReadAsArray()\n",
    "post_b11 = ds.GetRasterBand(4).ReadAsArray()\n",
    "post_scl = ds.GetRasterBand(6).ReadAsArray()\n",
    "\n",
    "width = ds.RasterXSize\n",
    "height = ds.RasterYSize\n",
    "\n",
    "input_geotransform = ds.GetGeoTransform()\n",
    "input_georef = ds.GetProjectionRef()\n",
    "#print(input_georef)\n",
    "proj = osr.SpatialReference(wkt=ds.GetProjection())\n",
    "espg = proj.GetAttrValue('AUTHORITY',1)\n",
    "print(espg) \n",
    "ds = None\n",
    "\n",
    "os.remove('S2_Pst_tmp.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvwi = lambda x,y: 0 if (x+y)==0  else float(x-y)/float(x+y)\n",
    "\n",
    "vfunc = np.vectorize(ndvwi, otypes=[np.float32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### NDWI with NIR (8) and SWIR (11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_ndwi2 = vfunc(pre_b08,pre_b11)\n",
    "post_ndwi2 = vfunc(post_b08,post_b11)\n",
    "\n",
    "pre_b11 = None\n",
    "post_b11 = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NDVI with NIR (8) and Red (4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_ndvi = vfunc(pre_b08,pre_b04)\n",
    "post_ndvi = vfunc(post_b08,post_b04)\n",
    "\n",
    "pre_b04 = None\n",
    "post_b04 = None\n",
    "\n",
    "pre_b08 = None\n",
    "post_b08 = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Burned Area computation: \n",
    "#### If NDWI i2 - NDWI i1 > 0.18 and If NDVI i2 - NDVI i1 > 0.19 then burned pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndwi_diff = pre_ndwi2  - post_ndwi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_diff = pre_ndvi - post_ndvi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = lambda x,y,z,m,n,p: 1 if ((x  > float(y)) & (z > float(m)) & ((n == 4) | (p == 4))) else 0\n",
    "                             \n",
    "vfunc_conditions = np.vectorize(conditions, otypes=[np.uint8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burned_0 = vfunc_conditions(ndwi_diff, ndwi_threshold['value'], ndvi_diff, ndvi_threshold['value'], pre_scl, post_scl )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_ndwi2 = None\n",
    "post_ndwi2 = None\n",
    "\n",
    "pre_ndvi = None\n",
    "post_ndvi = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exclude according to scene classifications:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where noData put burned=2 if burn then put burned=1 else burned=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brnd = lambda x,y,z: 2 if (x==0 or y==0 or x==1 or y==1 or x==6 or y==6 or x==7 or y==7 or x==8 or y==8 or x==9 or y==9) else z\n",
    "\n",
    "vfunc = np.vectorize(brnd, otypes=[np.uint8])\n",
    "\n",
    "burned = vfunc(pre_scl , post_scl, burned_0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burned_0 = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Write the burned area temp tiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date=(products[products['ordinal_type'] == 'Pre'].reset_index(drop=True)).iloc[0].startdate#[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_date=(products[products['ordinal_type'] == 'Pst'].reset_index(drop=True)).iloc[0].enddate#[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products.sort_values(by='startdate',ascending=True,inplace=True)\n",
    "\n",
    "masterID = products.iloc[0].identifier\n",
    "slaveID = products.iloc[1].identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Requested file name : 'Burned_Area_S2_{MasterId}_{SlaveId}.tif\n",
    "if products[products['ordinal_type'] == 'Pre'].identifier.count() == 1 and products[products['ordinal_type'] == 'Pst'].identifier.count() == 1:\n",
    "    temp_output_name_Burned_Area = 'temp_Burned_Area_S2_%s_%s.tif'%(masterID,slaveID)\n",
    "else:\n",
    "    #if inputs are mosaiced \n",
    "    temp_output_name_Burned_Area = 'temp_Burned_Area_S2_%s_%s.tif'%(start_date,end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_tif(burned, temp_output_name_Burned_Area, width, height, input_geotransform, input_georef)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Post-processing step: removing raster polygons smaller than the provided threshold size (in pixels) - if threshold=0 no post-proc will be applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if int(pp_threshold['value']) != 0:\n",
    "    \n",
    "    output_name_Burned_Area = '_'.join(temp_output_name_Burned_Area.split('_')[1:])\n",
    "    sieve_filter(temp_output_name_Burned_Area,\n",
    "                 output_name_Burned_Area, \n",
    "                 int(pp_threshold['value']))\n",
    "    os.remove(temp_output_name_Burned_Area)\n",
    "\n",
    "else:\n",
    "    shutil.move(temp_output_name_Burned_Area,\n",
    "                output_name_Burned_Area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_files.append(output_name_Burned_Area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating the mask for the burned area to polygonize only Burned area polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = gdal.Open(output_name_Burned_Area)\n",
    "    \n",
    "ba = ds.GetRasterBand(1).ReadAsArray()\n",
    "ds=None\n",
    "\n",
    "brnd_mask = lambda x: 1 if (x==1) else 0\n",
    "\n",
    "vfunc = np.vectorize(brnd_mask, otypes=[np.uint8])\n",
    "\n",
    "mask_burned_area = vfunc(ba)\n",
    "\n",
    "write_tif(mask_burned_area, 'MASK_burned_area.tif', width, height, input_geotransform, input_georef)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_detection_gp = polygonize(output_name_Burned_Area, 1, espg, mask='MASK_burned_area.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_files.append('polygonized.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### if we replace {'init':'epsg:{}'.format(epsg)} with new recommended 'epsg:{}', the axis order changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_detection_gp.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the result WKT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = gdal.Open(output_name_Burned_Area)\n",
    "ulx, xres, xskew, uly, yskew, yres  = src.GetGeoTransform()\n",
    "\n",
    "max_x = ulx + (src.RasterXSize * xres)\n",
    "min_y = uly + (src.RasterYSize * yres)\n",
    "min_x = ulx \n",
    "max_y = uly\n",
    "\n",
    "min_x, min_y, max_x, max_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = osr.SpatialReference()\n",
    "source.ImportFromWkt(src.GetProjection())\n",
    "\n",
    "target = osr.SpatialReference()\n",
    "target.ImportFromEPSG(4326)\n",
    "\n",
    "transform = osr.CoordinateTransformation(source, target)\n",
    "\n",
    "result_wkt = box(transform.TransformPoint(min_x, min_y)[1],\n",
    "                 transform.TransformPoint(min_x, min_y)[0],\n",
    "                 transform.TransformPoint(max_x, max_y)[1],\n",
    "                 transform.TransformPoint(max_x, max_y)[0]).wkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_wkt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the properties file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_format = '%Y-%m-%dT%H:%m:%SZ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index , item in enumerate(output_files):\n",
    "\n",
    "    if 'RGB' in item:\n",
    "        prod = slaveID\n",
    "        if 'Pre' in item[4:7]:\n",
    "            prod = masterID\n",
    "        title = 'Sentinel-2 RGB {}-event {} (B11, B12, B8A)'.format(item[4:7],prod)\n",
    "            \n",
    "    if 'Burned_Area_S2' in item:\n",
    "        title = 'Sentinel-2 burned area identification for pair {}/{}'.format(masterID,slaveID)\n",
    "        if 'temp_' in item:\n",
    "            title = 'Sentinel-2 burned area identification for pair {}/{} (pre-filtering)'.format(masterID,slaveID)\n",
    "    \n",
    "    if 'polygonized' in item:\n",
    "        title = 'Geojson with vectorization of bitmask burned=1/not burned=0/unkown=2 for pair {}/{}'.format(masterID,slaveID)\n",
    "        \n",
    "    \n",
    "    with open('{}.properties'.format(item), 'w') as file:\n",
    "        \n",
    "        file.write('title={}\\n'.format(title))\n",
    "        \n",
    "        if 'Pre-event' in title:\n",
    "            start_date_iso = pd.to_datetime(products.iloc[0].startdate).strftime(date_format)\n",
    "            end_date_iso = pd.to_datetime(products.iloc[0].enddate).strftime(date_format)\n",
    "            file.write('date={}/{}\\n'.format(start_date_iso,start_date_iso))\n",
    "        elif 'Pst-event' in title :\n",
    "            start_date_iso = pd.to_datetime(products.iloc[1].startdate).strftime(date_format)\n",
    "            end_date_iso = pd.to_datetime(products.iloc[1].enddate).strftime(date_format)\n",
    "            file.write('date={}/{}\\n'.format(end_date_iso,end_date_iso))\n",
    "        else:\n",
    "            start_date_iso = pd.to_datetime(products.iloc[0].startdate).strftime(date_format)\n",
    "            end_date_iso = pd.to_datetime(products.iloc[1].enddate).strftime(date_format)\n",
    "            file.write('date={}/{}\\n'.format(start_date_iso,end_date_iso))\n",
    "            \n",
    "        file.write('geometry={}'.format(result_wkt))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### License"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This work is licenced under a [Attribution-ShareAlike 4.0 International License (CC BY-SA 4.0)](http://creativecommons.org/licenses/by-sa/4.0/) \n",
    "\n",
    "YOU ARE FREE TO:\n",
    "\n",
    "* Share - copy and redistribute the material in any medium or format.\n",
    "* Adapt - remix, transform, and built upon the material for any purpose, even commercially.\n",
    "\n",
    "UNDER THE FOLLOWING TERMS:\n",
    "\n",
    "* Attribution - You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use.\n",
    "* ShareAlike - If you remix, transform, or build upon the material, you must distribute your contributions under the same license as the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_ewf_satcen_03_03_02",
   "language": "python",
   "name": "env_ewf_satcen_03_03_02"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
